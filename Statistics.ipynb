{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNwpHvMEeIXjdCAgChVH86T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kanchandhole/Statistic/blob/main/Statistics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.**Explain the different types of data (qualitative and quantitative) and provide examples of each. Discuss\n",
        "nominal, ordinal, interval, and ratio scales.\n",
        "\n",
        "Ans:-\n",
        "\n",
        "Data can be classified into two broad categories: **qualitative** and **quantitative**. Each of these categories has different types of measurements that help us understand and interpret the world around us.\n",
        "\n",
        "### 1. **Qualitative Data (Categorical Data)**:\n",
        "Qualitative data describes characteristics or qualities that cannot be measured numerically. Instead, it categorizes or classifies data based on attributes or labels.\n",
        "\n",
        "- **Examples**:\n",
        "  - **Colors** (e.g., red, blue, green)\n",
        "  - **Types of animals** (e.g., dog, cat, bird)\n",
        "  - **Gender** (e.g., male, female, non-binary)\n",
        "\n",
        "#### Types of Qualitative Data Scales:\n",
        "There are two main types of qualitative data scales:\n",
        "\n",
        "- **Nominal Scale**:\n",
        "  - This is the most basic level of measurement. It classifies data into distinct categories without any order or ranking.\n",
        "  - **Examples**:\n",
        "    - **Eye color**: brown, blue, green, etc.\n",
        "    - **Blood type**: A, B, AB, O\n",
        "  - These categories are just names, and no category is greater or lesser than another.\n",
        "\n",
        "- **Ordinal Scale**:\n",
        "  - This scale classifies data into categories with a meaningful order or ranking, but the differences between the categories are not uniform or measurable.\n",
        "  - **Examples**:\n",
        "    - **Ranks in a race**: 1st, 2nd, 3rd (but the time differences between ranks aren't equal).\n",
        "    - **Education level**: high school, bachelor's degree, master's degree, etc.\n",
        "  - While there is a sense of order, the distance between ranks isn’t consistent or measurable.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Quantitative Data (Numerical Data)**:\n",
        "Quantitative data consists of numerical values that can be measured and manipulated mathematically. It allows for counting or measuring something in a meaningful way.\n",
        "\n",
        "- **Examples**:\n",
        "  - **Height**: 170 cm, 180 cm\n",
        "  - **Age**: 23 years, 45 years\n",
        "  - **Income**: $30,000, $75,000\n",
        "\n",
        "#### Types of Quantitative Data Scales:\n",
        "Quantitative data can be measured on the following scales:\n",
        "\n",
        "- **Interval Scale**:\n",
        "  - In this scale, the data points are ordered, and the differences between values are meaningful. However, there is **no true zero point**, so you can’t make statements about absolute quantities. The intervals between numbers are consistent, but ratios are not meaningful.\n",
        "  - **Examples**:\n",
        "    - **Temperature in Celsius or Fahrenheit**: The difference between 30°C and 40°C is the same as the difference between 70°C and 80°C, but 0°C doesn't represent the absence of temperature.\n",
        "    - **IQ scores**: The difference between an IQ of 100 and 110 is the same as between 110 and 120, but there is no \"true\" zero in IQ measurement.\n",
        "\n",
        "- **Ratio Scale**:\n",
        "  - The ratio scale has all the properties of the interval scale, but it also has a **true zero point**. This means that you can make meaningful statements about ratios between values (e.g., one value is twice as large as another).\n",
        "  - **Examples**:\n",
        "    - **Height**: 0 cm represents the absence of height, and 180 cm is twice as high as 90 cm.\n",
        "    - **Weight**: 0 kg means no weight, and 60 kg is twice as heavy as 30 kg.\n",
        "    - **Income**: $0 represents no income, and $50,000 is twice as much as $25,000.\n",
        "\n",
        "---\n",
        "\n",
        "### Summary:\n",
        "\n",
        "- **Qualitative Data**:\n",
        "  - **Nominal**: Categories without order (e.g., colors, types of animals).\n",
        "  - **Ordinal**: Categories with a meaningful order, but no consistent differences (e.g., race ranking, education levels).\n",
        "\n",
        "- **Quantitative Data**:\n",
        "  - **Interval**: Numerical data with consistent differences, but no true zero (e.g., temperature, IQ scores).\n",
        "  - **Ratio**: Numerical data with consistent differences and a true zero point (e.g., height, weight, income).\n",
        "\n",
        "Understanding the type of data and scale is crucial in selecting the right statistical methods and tools for analysis."
      ],
      "metadata": {
        "id": "zgpUHK0H8Q5T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.**What are the measures of central tendency, and when should you use each? Discuss the mean, median,\n",
        "and mode with examples and situations where each is appropriate.\n",
        "\n",
        "**Ans:**\n",
        "**Measures of Central Tendency** are statistical values that describe the center or typical value of a dataset. They give us an idea of where the data points tend to cluster, helping us understand the distribution of the data. The three main measures of central tendency are the **mean**, **median**, and **mode**.\n",
        "\n",
        "### 1. **Mean (Average)**:\n",
        "The **mean** is the sum of all data points divided by the number of data points. It is the most commonly used measure of central tendency and works well when the data is symmetrically distributed.\n",
        "\n",
        "#### Formula:\n",
        "\\[\n",
        "\\text{Mean} = \\frac{\\sum \\text{(all data points)}}{n}\n",
        "\\]\n",
        "where \\(n\\) is the number of data points.\n",
        "\n",
        "#### Example:\n",
        "Consider the data set: 2, 4, 6, 8, 10.\n",
        "\n",
        "\\[\n",
        "\\text{Mean} = \\frac{2 + 4 + 6 + 8 + 10}{5} = \\frac{30}{5} = 6\n",
        "\\]\n",
        "The mean is 6.\n",
        "\n",
        "#### Appropriate Situations:\n",
        "- **Symmetric distributions**: The mean is best used when the data does not have extreme outliers or skewness.\n",
        "- **Large datasets**: The mean is most useful when working with large datasets that follow a normal or near-normal distribution.\n",
        "\n",
        "#### Limitations:\n",
        "- The **mean** can be heavily influenced by outliers or extreme values. For instance, in the dataset: 2, 4, 6, 8, 100, the mean is \\( \\frac{2 + 4 + 6 + 8 + 100}{5} = 24 \\), which is not representative of most of the data points.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Median**:\n",
        "The **median** is the middle value of a dataset when the values are arranged in ascending (or descending) order. If there’s an even number of data points, the median is the average of the two middle values.\n",
        "\n",
        "#### Example:\n",
        "Consider the data set: 2, 4, 6, 8, 10. (Already in order)\n",
        "\n",
        "The **median** is the middle value, which is 6.\n",
        "\n",
        "For an even dataset: 1, 3, 5, 7.  \n",
        "The median is the average of the two middle values:\n",
        "\\[\n",
        "\\text{Median} = \\frac{3 + 5}{2} = 4\n",
        "\\]\n",
        "\n",
        "#### Appropriate Situations:\n",
        "- **Skewed distributions**: The median is especially useful when the data contains outliers or is skewed. It is less influenced by extreme values.\n",
        "- **Ordinal data**: When dealing with ordinal data (e.g., rankings), the median is a better measure than the mean.\n",
        "\n",
        "#### Example of When to Use:\n",
        "In a dataset with extreme values, like income data (e.g., a few extremely high incomes), the **median** provides a better sense of the \"typical\" income because it is not skewed by those outliers.\n",
        "\n",
        "#### Limitations:\n",
        "- The **median** doesn’t reflect all data points, especially in smaller datasets. For example, in a dataset of ages: 5, 10, 100, the median is 10, which may not represent the distribution well.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Mode**:\n",
        "The **mode** is the value that appears most frequently in a dataset. A dataset may have **one mode** (unimodal), **two modes** (bimodal), or **more than two modes** (multimodal), or it may have **no mode** if no value repeats.\n",
        "\n",
        "#### Example:\n",
        "Consider the data set: 1, 2, 2, 3, 4.\n",
        "\n",
        "The **mode** is 2 because it occurs more frequently than the other numbers.\n",
        "\n",
        "#### Appropriate Situations:\n",
        "- **Categorical or nominal data**: The mode is particularly useful for categorical data, where we want to know which category occurs the most frequently.\n",
        "- **When data has a frequency distribution**: It’s useful when you're looking for the most common item or value in a dataset.\n",
        "  \n",
        "#### Example of When to Use:\n",
        "In a survey where people choose their favorite color from a set of options (red, blue, green, etc.), the **mode** will tell you which color was selected most frequently.\n",
        "\n",
        "#### Limitations:\n",
        "- The **mode** may not provide much insight if all data values are unique or if there are multiple modes.\n",
        "\n",
        "---\n",
        "\n",
        "### **Comparison and When to Use Each Measure**:\n",
        "\n",
        "- **Mean**:\n",
        "  - Use when: The data is approximately symmetrical and does not have extreme outliers.\n",
        "  - Best for: Interval or ratio data with no significant outliers.\n",
        "  - Example: Average test scores, average height of people.\n",
        "\n",
        "- **Median**:\n",
        "  - Use when: The data is skewed, contains outliers, or when the dataset is ordinal.\n",
        "  - Best for: Ordinal, interval, or ratio data with skewness or outliers.\n",
        "  - Example: Median income, median house price.\n",
        "\n",
        "- **Mode**:\n",
        "  - Use when: You are working with categorical data, or when you want to know the most common value.\n",
        "  - Best for: Nominal data or any data where you want to know the most frequent value.\n",
        "  - Example: Most popular product in a store, most frequent shoe size sold.\n"
      ],
      "metadata": {
        "id": "q9RSYIk_8ael"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.**Explain the concept of dispersion. How do variance and standard deviation measure the spread of data?\n",
        "\n",
        "**Ans:**\n",
        "\n",
        "### **Dispersion**:\n",
        "**Dispersion** refers to the extent to which data points in a dataset vary or spread out from the central value (such as the mean). It provides insight into how much the values in the dataset differ from the average and gives us an idea of the **degree of variability** in the data.\n",
        "\n",
        "A dataset with low dispersion means the values are closely clustered around the central value, while a dataset with high dispersion means the values are spread out more widely.\n",
        "\n",
        "### **Measures of Dispersion**:\n",
        "The two most common measures of dispersion are **variance** and **standard deviation**. Both measure the spread of the data, but they do so in different ways.\n",
        "\n",
        "---\n",
        "\n",
        "### 1. **Variance**:\n",
        "Variance measures the **average squared deviation** of each data point from the mean. It gives us an idea of how much the data points differ from the mean in a **squared unit**. The larger the variance, the more spread out the data points are.\n",
        "\n",
        "#### Formula for Variance:\n",
        "For a population, the variance (\\(\\sigma^2\\)) is calculated as:\n",
        "\n",
        "\\[\n",
        "\\sigma^2 = \\frac{\\sum (x_i - \\mu)^2}{N}\n",
        "\\]\n",
        "\n",
        "Where:\n",
        "- \\(x_i\\) = Each individual data point\n",
        "- \\(\\mu\\) = Mean of the dataset\n",
        "- \\(N\\) = Total number of data points\n",
        "\n",
        "For a **sample**, the formula is slightly adjusted to account for sample size:\n",
        "\n",
        "\\[\n",
        "s^2 = \\frac{\\sum (x_i - \\bar{x})^2}{n - 1}\n",
        "\\]\n",
        "\n",
        "Where:\n",
        "- \\(\\bar{x}\\) = Sample mean\n",
        "- \\(n\\) = Sample size\n",
        "\n",
        "#### Example of Variance:\n",
        "Consider the dataset: 2, 4, 6, 8, 10.\n",
        "\n",
        "1. **Mean** (\\(\\mu\\)) = \\( \\frac{2 + 4 + 6 + 8 + 10}{5} = 6 \\).\n",
        "2. Calculate each squared deviation from the mean:\n",
        "   - \\((2 - 6)^2 = 16\\)\n",
        "   - \\((4 - 6)^2 = 4\\)\n",
        "   - \\((6 - 6)^2 = 0\\)\n",
        "   - \\((8 - 6)^2 = 4\\)\n",
        "   - \\((10 - 6)^2 = 16\\)\n",
        "3. Sum of squared deviations: \\(16 + 4 + 0 + 4 + 16 = 40\\).\n",
        "4. Divide by the number of data points (\\(5\\)):\n",
        "   - **Variance** = \\( \\frac{40}{5} = 8 \\).\n",
        "\n",
        "#### Interpretation:\n",
        "A variance of 8 means that, on average, each data point is squared 8 units away from the mean. However, the units are squared (e.g., if the data were in meters, variance would be in square meters), which can make interpretation less intuitive.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Standard Deviation**:\n",
        "The **standard deviation** is the square root of the variance. It measures the **average distance** of each data point from the mean in the **same units** as the original data, making it more interpretable than variance.\n",
        "\n",
        "#### Formula for Standard Deviation:\n",
        "For a population, the standard deviation (\\(\\sigma\\)) is the square root of the variance:\n",
        "\n",
        "\\[\n",
        "\\sigma = \\sqrt{\\sigma^2}\n",
        "\\]\n",
        "\n",
        "For a sample, the standard deviation (\\(s\\)) is:\n",
        "\n",
        "\\[\n",
        "s = \\sqrt{s^2}\n",
        "\\]\n",
        "\n",
        "#### Example of Standard Deviation:\n",
        "Using the variance calculated earlier (8):\n",
        "\n",
        "\\[\n",
        "\\sigma = \\sqrt{8} \\approx 2.83\n",
        "\\]\n",
        "\n",
        "#### Interpretation:\n",
        "A standard deviation of 2.83 means that, on average, each data point is about 2.83 units away from the mean (6 in this case). Since the standard deviation is in the same units as the data, it's easier to understand than variance.\n",
        "\n",
        "---\n",
        "\n",
        "### **How Variance and Standard Deviation Measure the Spread of Data**:\n",
        "Both **variance** and **standard deviation** quantify how much the data points differ from the mean, but they do so differently:\n",
        "\n",
        "- **Variance** gives a measure of the spread in terms of squared units, which can make it less intuitive for direct interpretation, but it is useful for certain mathematical and statistical calculations.\n",
        "- **Standard Deviation** is often preferred because it provides a more **practical, interpretable value** that is in the same units as the data, making it easier to understand the typical distance from the mean.\n",
        "\n",
        "### **Key Differences**:\n",
        "- **Variance** is expressed in **squared units** of the original data, whereas **standard deviation** is in the **same units**.\n",
        "- **Standard deviation** is generally preferred in many contexts because it is easier to interpret and directly relates to the original scale of the data.\n",
        "\n",
        "\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "id": "-qtYWlAk9LWB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.**What is a box plot, and what can it tell you about the distribution of data?\n",
        "\n",
        "**Ans:**\n",
        "Box plots are used to show distributions of numeric data values, especially when you want to compare them between multiple groups. They are built to provide high-level information at a glance, offering general information about a group of data's symmetry, skew, variance, and outliers."
      ],
      "metadata": {
        "id": "v1c-S1It9qQW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.**Discuss the role of random sampling in making inferences about populations.\n",
        "\n",
        "**Ans:**\n",
        "Random sampling is a fundamental concept in statistics that plays a crucial role in making inferences about a population based on a sample. When we collect data, we rarely have access to an entire population, so we use random sampling to select a representative subset (sample) of the population, which helps us make conclusions or generalizations about the whole population.\n",
        "\n",
        "Random sampling is a technique in which every member of a population has an equal chance of being selected to be part of the sample. This process helps ensure that the sample is representative of the population, reducing the bias that can occur when only certain groups are selected. There are various types of random sampling, such as:\n",
        "\n",
        "Simple Random Sampling: Every individual in the population has an equal chance of being selected.\n",
        "Stratified Random Sampling: The population is divided into subgroups (strata), and random samples are taken from each subgroup.\n",
        "Systematic Sampling: Every\n",
        "𝑛\n",
        "n-th individual is selected from a list of the population.\n",
        "Cluster Sampling: The population is divided into clusters, and a random sample of clusters is selected to represent the population.\n"
      ],
      "metadata": {
        "id": "NuQek0KK-A_C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6.**Explain the concept of skewness and its types. How does skewness affect the interpretation of data?\n",
        "\n",
        "**Ans:**\n",
        "\n",
        "### **Skewness**:\n",
        "\n",
        "**Skewness** is a measure of the asymmetry or lopsidedness of a distribution. It tells us about the **direction** in which the data is stretched or biased. If a distribution is **not symmetric**, it is said to be skewed. Skewness affects the shape of the distribution and the interpretation of the data because it indicates whether the data has more extreme values on one side (either the left or right) compared to the other.\n",
        "\n",
        "### **Types of Skewness**:\n",
        "\n",
        "There are three main types of skewness:\n",
        "\n",
        "---\n",
        "\n",
        "### 1. **Positive Skew (Right Skew)**:\n",
        "A distribution is said to be **positively skewed** or **right-skewed** when the right tail (the larger values) is longer or more stretched out than the left tail. In other words, the **bulk of the data** is concentrated on the **left side** of the distribution, with a few extremely high values (outliers) pulling the mean to the right.\n",
        "\n",
        "- **Characteristics**:\n",
        "  - **Mean > Median > Mode**.\n",
        "  - The data is clustered on the left side of the distribution.\n",
        "  - There are relatively fewer high values or outliers.\n",
        "  \n",
        "- **Example**:\n",
        "  - Income distribution often exhibits positive skew. A large portion of the population may have moderate incomes, but a few individuals may have very high incomes, causing the mean to be pulled to the right.\n",
        "\n",
        "- **Effect on Interpretation**:\n",
        "  - In a positively skewed distribution, the **mean** is greater than the **median**, and the median is typically a better measure of central tendency. The **outliers** or extremely high values can distort the mean, making it appear higher than most of the data.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Negative Skew (Left Skew)**:\n",
        "A distribution is said to be **negatively skewed** or **left-skewed** when the left tail (the smaller values) is longer or more stretched out than the right tail. In other words, the **bulk of the data** is concentrated on the **right side** of the distribution, with a few extremely low values (outliers) pulling the mean to the left.\n",
        "\n",
        "- **Characteristics**:\n",
        "  - **Mean < Median < Mode**.\n",
        "  - The data is clustered on the right side of the distribution.\n",
        "  - There are relatively fewer low values or outliers.\n",
        "  \n",
        "- **Example**:\n",
        "  - A person's age when they first start a business might be negatively skewed. Most entrepreneurs start businesses in their 30s or 40s, but a few may start much earlier or much later, creating a long tail on the left side.\n",
        "\n",
        "- **Effect on Interpretation**:\n",
        "  - In a negatively skewed distribution, the **mean** is smaller than the **median**, and the median is again a better measure of central tendency. The **outliers** or extremely low values can pull the mean down, making it appear smaller than most of the data.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **No Skew (Symmetry or Zero Skew)**:\n",
        "A distribution is said to have **no skew** or be **symmetric** when the left and right tails are of equal length, meaning the data is evenly distributed on both sides of the central value.\n",
        "\n",
        "- **Characteristics**:\n",
        "  - **Mean = Median = Mode**.\n",
        "  - The distribution is perfectly balanced with a symmetrical shape.\n",
        "\n",
        "- **Example**:\n",
        "  - A perfectly normal distribution (bell curve) is symmetric and has no skew.\n",
        "\n",
        "- **Effect on Interpretation**:\n",
        "  - For a symmetric distribution, the **mean**, **median**, and **mode** will be the same, and either measure can be used to describe the central tendency accurately.\n",
        "\n",
        "---\n",
        "\n",
        "### **Measuring Skewness**:\n",
        "\n",
        "Skewness can be quantitatively measured using the **skewness coefficient**, which helps determine the direction and degree of skewness in a dataset:\n",
        "\n",
        "\\[\n",
        "\\text{Skewness} = \\frac{n}{(n-1)(n-2)} \\sum \\left( \\frac{x_i - \\bar{x}}{s} \\right)^3\n",
        "\\]\n",
        "Where:\n",
        "- \\(n\\) is the number of data points,\n",
        "- \\(x_i\\) is each individual data point,\n",
        "- \\(\\bar{x}\\) is the sample mean,\n",
        "- \\(s\\) is the sample standard deviation.\n",
        "\n",
        "- A skewness value of **0** indicates no skew (symmetric distribution).\n",
        "- A positive skewness value indicates **positive skew (right skew)**.\n",
        "- A negative skewness value indicates **negative skew (left skew)**.\n",
        "\n",
        "---\n",
        "\n",
        "### **How Skewness Affects the Interpretation of Data**:\n",
        "\n",
        "1. **Impacts Measures of Central Tendency**:\n",
        "   - **Skewness affects the relationship between the mean, median, and mode**. In a **positively skewed** distribution, the mean is pulled to the right of the median, making the mean appear larger than the median. In a **negatively skewed** distribution, the mean is pulled to the left of the median, making the mean appear smaller.\n",
        "   - For skewed distributions, the **median** is often preferred as a measure of central tendency, as it is less influenced by extreme values (outliers) compared to the mean.\n",
        "\n",
        "2. **Understanding the Spread of the Data**:\n",
        "   - **Skewness provides insights into the spread of data**. A positive skew suggests that the majority of data points are clustered toward the lower end, but there are a few extreme high values (outliers) pulling the distribution to the right. Similarly, a negative skew suggests that the majority of data points are concentrated at the higher end, with a few extreme low values pulling the distribution to the left.\n",
        "\n",
        "3. **Decision Making and Risk Assessment**:\n",
        "   - In **business or finance**, understanding skewness can help in **risk assessment**. For example, in investment, a **positively skewed** return distribution might indicate that most of the time, returns are moderate, but occasionally there might be very high returns, which can influence risk-taking decisions. On the other hand, a **negatively skewed** return distribution might signal frequent small gains with the occasional large loss, influencing more conservative decisions.\n",
        "\n",
        "4. **Choice of Statistical Techniques**:\n",
        "   - **Skewness affects the choice of statistical methods**. Many statistical techniques, like **linear regression**, assume normality (no skew). If the data is highly skewed, **transformations** (e.g., logarithmic or square root transformations) may be necessary to normalize the data before performing certain analyses.\n",
        "\n",
        "5. **Data Interpretation in Research**:\n",
        "   - **Skewness provides context for interpreting research results**. For example, in social science research, if the distribution of a certain variable (e.g., household income) is skewed, researchers will interpret the mean income cautiously, as it may not be representative of most people’s incomes."
      ],
      "metadata": {
        "id": "HSUnMuQm-hCi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7.**What is the interquartile range (IQR), and how is it used to detect outliers?\n",
        "\n",
        "**Ans:**\n",
        "\n",
        "### **Interquartile Range (IQR)**:\n",
        "\n",
        "The **Interquartile Range (IQR)** is a measure of statistical dispersion that describes the **range within which the middle 50%** of the data lies. It is the difference between the **third quartile (Q3)** and the **first quartile (Q1)**, effectively capturing the spread of the central half of the data.\n",
        "\n",
        "\\[\n",
        "IQR = Q3 - Q1\n",
        "\\]\n",
        "\n",
        "Where:\n",
        "- **Q1** (First Quartile) is the median of the lower half of the dataset (25th percentile).\n",
        "- **Q3** (Third Quartile) is the median of the upper half of the dataset (75th percentile).\n",
        "\n",
        "The IQR is a useful tool for understanding the **spread** of the middle 50% of the data and for detecting **outliers** in a dataset.\n",
        "\n",
        "---\n",
        "\n",
        "### **How to Calculate IQR**:\n",
        "To calculate the IQR, follow these steps:\n",
        "1. **Order the data**: Arrange the data points in increasing order.\n",
        "2. **Find the median**: Identify the **median** (Q2), which divides the data into two halves.\n",
        "3. **Find Q1 (First Quartile)**: This is the median of the lower half of the data (values less than Q2).\n",
        "4. **Find Q3 (Third Quartile)**: This is the median of the upper half of the data (values greater than Q2).\n",
        "5. **Calculate IQR**: Subtract Q1 from Q3 (IQR = Q3 - Q1).\n",
        "\n",
        "---\n",
        "\n",
        "### **Using IQR to Detect Outliers**:\n",
        "\n",
        "The IQR is commonly used to detect **outliers**—data points that are significantly different from most of the other values in the dataset. Outliers can distort the analysis, so it’s important to identify them.\n",
        "\n",
        "Outliers are typically defined as values that are either **too high** or **too low** compared to the rest of the data. A common method for detecting outliers involves using **1.5 times the IQR**.\n",
        "\n",
        "### **Steps to Detect Outliers Using IQR**:\n",
        "\n",
        "1. **Find the lower bound**:\n",
        "   \\[\n",
        "   \\text{Lower Bound} = Q1 - 1.5 \\times IQR\n",
        "   \\]\n",
        "   \n",
        "2. **Find the upper bound**:\n",
        "   \\[\n",
        "   \\text{Upper Bound} = Q3 + 1.5 \\times IQR\n",
        "   \\]\n",
        "   \n",
        "3. **Identify outliers**:\n",
        "   - Any data point **below the lower bound** or **above the upper bound** is considered an **outlier**.\n",
        "   \n",
        "Outliers are often plotted individually, and points that fall outside the range defined by these bounds are typically flagged as extreme values.\n",
        "\n",
        "---\n",
        "\n",
        "### **Example**:\n",
        "\n",
        "Consider the following dataset:\n",
        "\n",
        "**Data**: 3, 7, 8, 12, 13, 16, 22, 25, 29, 34, 45\n",
        "\n",
        "1. **Order the data**:\n",
        "   - 3, 7, 8, 12, 13, 16, 22, 25, 29, 34, 45\n",
        "\n",
        "2. **Find the median (Q2)**:\n",
        "   - The median is 16 (the middle value).\n",
        "\n",
        "3. **Find Q1 (First Quartile)**:\n",
        "   - The lower half of the data is 3, 7, 8, 12, 13.\n",
        "   - The median of the lower half (Q1) is **8**.\n",
        "\n",
        "4. **Find Q3 (Third Quartile)**:\n",
        "   - The upper half of the data is 22, 25, 29, 34, 45.\n",
        "   - The median of the upper half (Q3) is **29**.\n",
        "\n",
        "5. **Calculate IQR**:\n",
        "   \\[\n",
        "   IQR = Q3 - Q1 = 29 - 8 = 21\n",
        "   \\]\n",
        "\n",
        "6. **Calculate the lower and upper bounds**:\n",
        "   - **Lower Bound** = \\( 8 - 1.5 \\times 21 = 8 - 31.5 = -23.5 \\)\n",
        "   - **Upper Bound** = \\( 29 + 1.5 \\times 21 = 29 + 31.5 = 60.5 \\)\n",
        "\n",
        "7. **Identify outliers**:\n",
        "   - Any data point **below -23.5** or **above 60.5** is an outlier.\n",
        "   - In this dataset, all values lie between -23.5 and 60.5, so there are **no outliers**.\n",
        "\n",
        "---\n",
        "\n",
        "### **Visualizing Outliers Using a Box Plot**:\n",
        "\n",
        "In a **box plot**, the IQR is used to draw the **box**, which represents the middle 50% of the data (from Q1 to Q3). The **whiskers** extend to the lowest and highest data points within the bounds of \\( Q1 - 1.5 \\times IQR \\) and \\( Q3 + 1.5 \\times IQR \\). Any data points beyond the whiskers are considered **outliers**.\n"
      ],
      "metadata": {
        "id": "l1RQvWKm-96x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8.**Discuss the conditions under which the binomial distribution is used.\n",
        "\n",
        "**Ans:**\n",
        "\n",
        "### **Conditions for Using the Binomial Distribution**:\n",
        "\n",
        "The **binomial distribution** is a discrete probability distribution that describes the number of successes in a fixed number of independent trials, where each trial has two possible outcomes (commonly referred to as \"success\" and \"failure\"). For the binomial distribution to be applicable, certain conditions must be met. These conditions ensure that the distribution models the situation correctly.\n",
        "\n",
        "---\n",
        "\n",
        "### **Key Conditions for Using the Binomial Distribution**:\n",
        "\n",
        "1. **Fixed Number of Trials (n)**:\n",
        "   - The experiment or process must consist of a fixed number of trials (denoted as **n**).\n",
        "   - Each trial is independent of the others, and the number of trials must be known in advance.\n",
        "\n",
        "   - **Example**: Flipping a coin 10 times. Here, the number of trials (n) is 10.\n",
        "\n",
        "2. **Two Possible Outcomes per Trial**:\n",
        "   - Each trial must result in one of two outcomes, often labeled as **success** and **failure**. These outcomes are mutually exclusive, meaning that only one outcome can occur at any given time.\n",
        "   - The outcomes could be anything, but they must be binary. For instance, a successful test result or a failed test, or flipping heads (success) or tails (failure) in a coin flip.\n",
        "\n",
        "   - **Example**: In a coin flip, the two possible outcomes are heads (success) and tails (failure).\n",
        "\n",
        "3. **Constant Probability of Success (p)**:\n",
        "   - The probability of success, denoted as **p**, must remain constant across all trials. Similarly, the probability of failure is **1 - p**.\n",
        "   - This means that each trial is identical, with the same chance of success and failure.\n",
        "\n",
        "   - **Example**: If you are flipping a fair coin, the probability of getting heads (success) is 0.5, and this probability is the same for each flip.\n",
        "\n",
        "4. **Independence of Trials**:\n",
        "   - The trials must be **independent**, meaning that the outcome of one trial does not affect the outcome of another trial. The probability of success or failure remains unchanged regardless of the results of previous trials.\n",
        "   \n",
        "   - **Example**: Flipping a coin 10 times. The result of one flip (heads or tails) does not influence the result of the next flip. Each flip is independent of the others.\n",
        "\n",
        "5. **Random Variable Counting Successes**:\n",
        "   - The random variable of interest is the **number of successes** (denoted as **X**) in the **n** trials.\n",
        "   - The binomial distribution gives the probability of observing a certain number of successes in a fixed number of trials, where successes are counted as occurrences of the \"success\" outcome.\n",
        "\n",
        "   - **Example**: In a survey where you're asked if you like a particular product (Yes = Success, No = Failure), the random variable \\(X\\) could represent the number of people who answer \"Yes\" out of the total number of people surveyed.\n",
        "\n",
        "---\n",
        "\n",
        "### **The Binomial Distribution Formula**:\n",
        "\n",
        "If all of the above conditions are met, the probability of getting exactly **k** successes (where **k** is a specific number) out of **n** trials can be calculated using the **binomial probability formula**:\n",
        "\n",
        "\\[\n",
        "P(X = k) = \\binom{n}{k} p^k (1 - p)^{n - k}\n",
        "\\]\n",
        "\n",
        "Where:\n",
        "- \\( \\binom{n}{k} \\) is the **binomial coefficient**, which represents the number of ways to choose **k** successes from **n** trials. It is calculated as:\n",
        "  \\[\n",
        "  \\binom{n}{k} = \\frac{n!}{k!(n-k)!}\n",
        "  \\]\n",
        "- **p** is the probability of success on a single trial.\n",
        "- **k** is the number of successes.\n",
        "- **n** is the number of trials.\n",
        "\n",
        "The binomial distribution can also be described using a **binomial random variable** \\(X\\), which follows the distribution \\(X \\sim \\text{Binomial}(n, p)\\), where **n** is the number of trials and **p** is the probability of success.\n",
        "\n",
        "---\n",
        "\n",
        "### **Examples of Binomial Distribution**:\n",
        "\n",
        "1. **Coin Tossing**:\n",
        "   - Suppose you toss a fair coin 5 times, and you're interested in the number of heads (successes) that occur.\n",
        "   - Here, \\(n = 5\\), \\(p = 0.5\\), and you're interested in the number of heads (k successes) out of the 5 trials.\n",
        "   - You can calculate the probability of getting exactly 3 heads using the binomial distribution formula.\n",
        "\n",
        "2. **Product Testing**:\n",
        "   - Imagine a factory producing light bulbs, and you want to know the probability of finding exactly 3 defective light bulbs in a sample of 10 light bulbs.\n",
        "   - Each light bulb has a 5% chance of being defective (p = 0.05), and you are sampling 10 bulbs (n = 10).\n",
        "   - You can use the binomial distribution to calculate the probability of exactly 3 defective bulbs.\n",
        "\n",
        "3. **Survey Responses**:\n",
        "   - A researcher surveys 100 people and asks if they like a new product. Each person has a 70% chance of saying yes (p = 0.7), and the survey is repeated with 100 participants (n = 100).\n",
        "   - You can use the binomial distribution to calculate the probability of getting exactly 75 \"yes\" responses.\n",
        "\n",
        "---\n",
        "\n",
        "### **When Not to Use the Binomial Distribution**:\n",
        "\n",
        "1. **Non-fixed number of trials**: If the number of trials is not fixed and varies in each experiment, the binomial distribution cannot be used. For example, if you're conducting an experiment that ends when a certain number of successes occurs (like a waiting time problem), you would use a **negative binomial distribution** instead.\n",
        "\n",
        "2. **More than two outcomes per trial**: If each trial has more than two possible outcomes, the binomial distribution does not apply. For example, a multi-choice test where each question has multiple possible answers would not follow a binomial distribution.\n",
        "\n",
        "3. **Dependent trials**: If the trials are not independent (e.g., sampling without replacement), the binomial distribution may not be appropriate. In these cases, adjustments like the **hypergeometric distribution** may be needed.\n"
      ],
      "metadata": {
        "id": "lsxelmpj_V5a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9.**Explain the properties of the normal distribution and the empirical rule (68-95-99.7 rule).\n",
        "\n",
        "**Ans:**\n",
        "\n",
        "The normal distribution, often called the \"bell curve,\" is a symmetrical distribution where most data points cluster around the mean, with progressively fewer data points further away from the mean; the empirical rule (or 68-95-99.7 rule) states that in a normal distribution, approximately 68% of data falls within 1 standard deviation of the mean, 95% falls within 2 standard deviations, and 99.7% falls within 3 standard deviations of the mean.\n",
        "Key points about the normal distribution:\n",
        "Bell-shaped curve:\n",
        "The visual representation of a normal distribution is a bell-shaped curve, with the highest point at the mean.\n",
        "Symmetry:\n",
        "The distribution is symmetrical, meaning the data is evenly distributed on either side of the mean.\n",
        "Mean, median, mode are equal:\n",
        "In a perfect normal distribution, the mean, median, and mode are all the same value.\n",
        "Explanation of the empirical rule:\n",
        "68% within 1 standard deviation:\n",
        "This means that roughly 68% of data points in a normal distribution will lie within one standard deviation above and below the mean.\n",
        "95% within 2 standard deviations:\n",
        "Approximately 95% of data points will fall within two standard deviations from the mean.\n",
        "99.7% within 3 standard deviations:\n",
        "Almost all (99.7%) data points will be situated within three standard deviations of the mean.\n",
        "Example:\n",
        "Imagine a dataset representing the heights of adult males in a population. If this data is normally distributed, and the average height is 5'10\" with a standard deviation of 3 inches, then:\n",
        "Around 68% of men would be between 5'9\" and 5'11\" (within 1 standard deviation).\n",
        "Approximately 95% of men would be between 5'6\" and 6'2\" (within 2 standard deviations).\n",
        "Nearly all men would be between 5'3\" and 6'5\" (within 3 standard deviations)."
      ],
      "metadata": {
        "id": "T_mwqgnD_WXC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10.**Provide a real-life example of a Poisson process and calculate the probability for a specific event.\n",
        "\n",
        "**Ans:**\n",
        "\n",
        "### **Real-Life Example of a Poisson Process**:\n",
        "\n",
        "A **Poisson process** is a statistical model that describes the occurrence of events happening randomly over a fixed interval of time or space, where these events occur independently of each other, and the rate of occurrence is constant.\n",
        "\n",
        "One classic real-life example of a Poisson process is the **number of phone calls received by a call center** in a given hour. Let's assume that, on average, the call center receives **6 calls per hour**.\n",
        "\n",
        "---\n",
        "\n",
        "### **Defining the Parameters**:\n",
        "In this case:\n",
        "- **Rate (λ)**: The average number of calls received per hour = 6 calls/hour.\n",
        "- **Time Interval (T)**: We will calculate the probability for a specific event within a one-hour period.\n",
        "\n",
        "The **Poisson distribution** can be used to calculate the probability of receiving a specific number of calls in a fixed period. The probability mass function for the Poisson distribution is given by:\n",
        "\n",
        "\\[\n",
        "P(X = k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}\n",
        "\\]\n",
        "\n",
        "Where:\n",
        "- \\( P(X = k) \\) is the probability of observing **k** events (calls, in this case).\n",
        "- \\( \\lambda \\) is the average rate of occurrence (6 calls per hour).\n",
        "- \\( k \\) is the number of occurrences (the specific number of calls we want to calculate the probability for).\n",
        "- \\( e \\) is Euler's number, approximately equal to 2.71828.\n",
        "\n",
        "---\n",
        "\n",
        "### **Example Calculation**:\n",
        "\n",
        "Let's calculate the probability that the call center receives exactly **4 calls** in one hour.\n",
        "\n",
        "- **λ = 6** (average number of calls per hour).\n",
        "- **k = 4** (we are interested in the probability of exactly 4 calls).\n",
        "\n",
        "Using the Poisson distribution formula:\n",
        "\n",
        "\\[\n",
        "P(X = 4) = \\frac{6^4 e^{-6}}{4!}\n",
        "\\]\n",
        "\n",
        "First, calculate each part:\n",
        "- \\( 6^4 = 1296 \\)\n",
        "- \\( e^{-6} \\approx 0.00247875 \\)\n",
        "- \\( 4! = 4 \\times 3 \\times 2 \\times 1 = 24 \\)\n",
        "\n",
        "Now substitute the values into the formula:\n",
        "\n",
        "\\[\n",
        "P(X = 4) = \\frac{1296 \\times 0.00247875}{24}\n",
        "\\]\n",
        "\n",
        "\\[\n",
        "P(X = 4) \\approx \\frac{3.216}{24} \\approx 0.134\n",
        "\\]\n",
        "\n",
        "Thus, the probability that the call center receives exactly 4 calls in one hour is approximately **0.134** or **13.4%**.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "CcsM5pevAGOL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11.**Explain what a random variable is and differentiate between discrete and continuous random variables.\n",
        "\n",
        "**Ans:**\n",
        "\n",
        "### **What is a Random Variable?**\n",
        "\n",
        "A **random variable** is a numerical outcome of a random process or experiment. It is a function that assigns a real number to each possible outcome in a sample space. Random variables are central to probability theory and statistics because they allow us to model and analyze uncertainty in various situations.\n",
        "\n",
        "There are two main types of random variables:\n",
        "- **Discrete Random Variables**\n",
        "- **Continuous Random Variables**\n",
        "\n",
        "Each type of random variable behaves differently, and they are used to model different types of real-world phenomena.\n",
        "\n",
        "---\n",
        "\n",
        "### **1. Discrete Random Variables**:\n",
        "\n",
        "A **discrete random variable** is a random variable that can take on **a countable number of distinct values**. These values are often integers, and the set of possible outcomes is finite or countably infinite. Discrete random variables are typically used in situations where the outcomes can be listed or counted.\n",
        "\n",
        "#### **Characteristics of Discrete Random Variables**:\n",
        "- The possible values of the random variable can be counted.\n",
        "- The random variable takes specific, distinct values (e.g., 0, 1, 2, 3, ...).\n",
        "- There are gaps between the values (no intermediate values between them).\n",
        "- Probabilities for each value can be assigned using a **probability mass function (PMF)**.\n",
        "\n",
        "#### **Examples of Discrete Random Variables**:\n",
        "- **Number of heads in 5 coin flips**: The random variable can take values such as 0, 1, 2, 3, 4, or 5.\n",
        "- **Number of customers arriving at a store in a given hour**: This could take values such as 0, 1, 2, ..., up to a certain maximum.\n",
        "- **Number of defects in a batch of products**: This could be 0, 1, 2, 3, and so on.\n",
        "\n",
        "#### **Probability Distribution**:\n",
        "The probability distribution of a discrete random variable specifies the probabilities for each possible outcome. For example, in a fair coin toss, if \\( X \\) is the random variable representing the number of heads in a single flip, the possible values of \\( X \\) are 0 (tails) and 1 (heads), with probabilities:\n",
        "- \\( P(X = 0) = 0.5 \\)\n",
        "- \\( P(X = 1) = 0.5 \\)\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Continuous Random Variables**:\n",
        "\n",
        "A **continuous random variable** is a random variable that can take on **an infinite number of values within a given range**. The values are not countable, and there are infinitely many possible outcomes, typically within an interval. Continuous random variables are used to model quantities that can take any value within a given range, often involving measurements.\n",
        "\n",
        "#### **Characteristics of Continuous Random Variables**:\n",
        "- The random variable can take any value within an interval or range of real numbers.\n",
        "- There are **infinitely many possible values** in any given range (e.g., between 0 and 1, between 0 and 1000).\n",
        "- The probability of the variable taking any specific value is **zero**, because there are infinitely many possibilities. Instead, we use a **probability density function (PDF)** to describe the probability of the variable falling within a specific range.\n",
        "\n",
        "#### **Examples of Continuous Random Variables**:\n",
        "- **Height of a person**: The height could be 5.6 feet, 5.67 feet, 5.675 feet, and so on. There is no distinct gap between possible heights.\n",
        "- **Time taken to complete a task**: The time could be 5.3 minutes, 5.32 minutes, or 5.321 minutes, etc.\n",
        "- **Temperature**: The temperature could take any value within a certain range, such as between 20°C and 30°C.\n",
        "\n",
        "#### **Probability Distribution**:\n",
        "For continuous random variables, we use a **probability density function (PDF)** rather than a probability mass function. The probability that a continuous random variable \\( X \\) takes a specific value \\( x \\) is **zero** because there are infinitely many possible values. Instead, we compute the **probability that \\( X \\) falls within a certain range**, using the integral of the PDF.\n",
        "\n",
        "For example, if \\( X \\) is the height of a person, the probability that \\( X \\) falls between 5.5 and 6.0 feet might be calculated as the area under the PDF curve between these values.\n",
        "\n",
        "---\n",
        "\n",
        "### **Differences Between Discrete and Continuous Random Variables**:\n",
        "\n",
        "| **Characteristic**                  | **Discrete Random Variable**                 | **Continuous Random Variable**               |\n",
        "|-------------------------------------|----------------------------------------------|---------------------------------------------|\n",
        "| **Possible Values**                 | Countable (finite or countably infinite)      | Uncountable (infinite within a range)       |\n",
        "| **Type of Data**                    | Integer values (whole numbers)                | Real numbers (any value in a range)         |\n",
        "| **Example**                          | Number of heads in a coin toss, number of calls received | Height, weight, time, temperature           |\n",
        "| **Probability Distribution**        | Probability mass function (PMF)              | Probability density function (PDF)          |\n",
        "| **Probability of a Specific Value** | Non-zero probability for each value          | Probability of a specific value is zero; we compute probability within ranges |\n",
        "| **Representation**                  | List of probabilities for each possible value | Area under the curve represents probability |\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "is-gMpFyAW89"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**12.**Provide an example dataset, calculate both covariance and correlation, and interpret the results.\n",
        "\n",
        "**Ans:**\n",
        "\n",
        "### **Example Dataset:**\n",
        "\n",
        "Let’s use a simple dataset of two variables: **X** (number of hours studied) and **Y** (score on an exam). We want to calculate both the **covariance** and **correlation** between these two variables to understand their relationship.\n",
        "\n",
        "| Student | Hours Studied (X) | Exam Score (Y) |\n",
        "|---------|-------------------|----------------|\n",
        "| 1       | 2                 | 50             |\n",
        "| 2       | 3                 | 60             |\n",
        "| 3       | 4                 | 70             |\n",
        "| 4       | 5                 | 80             |\n",
        "| 5       | 6                 | 90             |\n",
        "\n",
        "### **Step 1: Calculate Covariance**\n",
        "\n",
        "#### **Covariance Formula:**\n",
        "The covariance between two variables \\( X \\) and \\( Y \\) is given by:\n",
        "\n",
        "\\[\n",
        "\\text{Cov}(X, Y) = \\frac{1}{n} \\sum_{i=1}^{n} (X_i - \\bar{X})(Y_i - \\bar{Y})\n",
        "\\]\n",
        "\n",
        "Where:\n",
        "- \\( X_i \\) and \\( Y_i \\) are the individual values of \\( X \\) and \\( Y \\).\n",
        "- \\( \\bar{X} \\) and \\( \\bar{Y} \\) are the means (averages) of \\( X \\) and \\( Y \\), respectively.\n",
        "- \\( n \\) is the number of data points.\n",
        "\n",
        "#### **Step 1.1: Calculate the means of X and Y**\n",
        "- Mean of \\( X \\) (\\( \\bar{X} \\)):\n",
        "\n",
        "\\[\n",
        "\\bar{X} = \\frac{2 + 3 + 4 + 5 + 6}{5} = \\frac{20}{5} = 4\n",
        "\\]\n",
        "\n",
        "- Mean of \\( Y \\) (\\( \\bar{Y} \\)):\n",
        "\n",
        "\\[\n",
        "\\bar{Y} = \\frac{50 + 60 + 70 + 80 + 90}{5} = \\frac{350}{5} = 70\n",
        "\\]\n",
        "\n",
        "#### **Step 1.2: Calculate the deviations from the mean for each pair of data points**\n",
        "\n",
        "| Student | \\( X_i \\) | \\( Y_i \\) | \\( X_i - \\bar{X} \\) | \\( Y_i - \\bar{Y} \\) | \\( (X_i - \\bar{X})(Y_i - \\bar{Y}) \\) |\n",
        "|---------|----------|----------|---------------------|---------------------|------------------------------------|\n",
        "| 1       | 2        | 50       | 2 - 4 = -2          | 50 - 70 = -20       | (-2)(-20) = 40                    |\n",
        "| 2       | 3        | 60       | 3 - 4 = -1          | 60 - 70 = -10       | (-1)(-10) = 10                    |\n",
        "| 3       | 4        | 70       | 4 - 4 = 0           | 70 - 70 = 0         | (0)(0) = 0                        |\n",
        "| 4       | 5        | 80       | 5 - 4 = 1           | 80 - 70 = 10        | (1)(10) = 10                      |\n",
        "| 5       | 6        | 90       | 6 - 4 = 2           | 90 - 70 = 20        | (2)(20) = 40                      |\n",
        "\n",
        "#### **Step 1.3: Sum up the products of deviations**\n",
        "\n",
        "\\[\n",
        "\\sum (X_i - \\bar{X})(Y_i - \\bar{Y}) = 40 + 10 + 0 + 10 + 40 = 100\n",
        "\\]\n",
        "\n",
        "#### **Step 1.4: Calculate Covariance**\n",
        "\n",
        "Now, divide the sum by the number of data points \\( n \\):\n",
        "\n",
        "\\[\n",
        "\\text{Cov}(X, Y) = \\frac{100}{5} = 20\n",
        "\\]\n",
        "\n",
        "### **Step 2: Calculate Correlation**\n",
        "\n",
        "#### **Correlation Formula:**\n",
        "The **correlation** between two variables \\( X \\) and \\( Y \\) is given by:\n",
        "\n",
        "\\[\n",
        "r = \\frac{\\text{Cov}(X, Y)}{\\sigma_X \\sigma_Y}\n",
        "\\]\n",
        "\n",
        "Where:\n",
        "- \\( \\text{Cov}(X, Y) \\) is the covariance we just calculated.\n",
        "- \\( \\sigma_X \\) and \\( \\sigma_Y \\) are the standard deviations of \\( X \\) and \\( Y \\), respectively.\n",
        "\n",
        "#### **Step 2.1: Calculate the standard deviations of X and Y**\n",
        "\n",
        "First, we need to calculate the variances of \\( X \\) and \\( Y \\), then take the square roots to get the standard deviations.\n",
        "\n",
        "- **Variance of X**:\n",
        "\\[\n",
        "\\text{Var}(X) = \\frac{1}{n} \\sum_{i=1}^{n} (X_i - \\bar{X})^2\n",
        "\\]\n",
        "\\[\n",
        "\\text{Var}(X) = \\frac{(-2)^2 + (-1)^2 + 0^2 + 1^2 + 2^2}{5} = \\frac{4 + 1 + 0 + 1 + 4}{5} = \\frac{10}{5} = 2\n",
        "\\]\n",
        "\\[\n",
        "\\sigma_X = \\sqrt{2} \\approx 1.414\n",
        "\\]\n",
        "\n",
        "- **Variance of Y**:\n",
        "\\[\n",
        "\\text{Var}(Y) = \\frac{1}{n} \\sum_{i=1}^{n} (Y_i - \\bar{Y})^2\n",
        "\\]\n",
        "\\[\n",
        "\\text{Var}(Y) = \\frac{(-20)^2 + (-10)^2 + 0^2 + 10^2 + 20^2}{5} = \\frac{400 + 100 + 0 + 100 + 400}{5} = \\frac{1000}{5} = 200\n",
        "\\]\n",
        "\\[\n",
        "\\sigma_Y = \\sqrt{200} \\approx 14.142\n",
        "\\]\n",
        "\n",
        "#### **Step 2.2: Calculate the correlation**\n",
        "\n",
        "Now we can calculate the correlation:\n",
        "\n",
        "\\[\n",
        "r = \\frac{20}{1.414 \\times 14.142} = \\frac{20}{20} = 1\n",
        "\\]"
      ],
      "metadata": {
        "id": "iK_J_mL5BAoY"
      }
    }
  ]
}